# -*- coding: utf-8 -*-
"""progetto_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12NvChpMJt38n4sMQH3Ab5n9gvZFxx_d9
"""

import tensorflow as tf
from tensorflow import keras

import numpy as np
from numpy import array

print(tf.__version__)

"""Importo cartella di tutti gli esercizi matematici, zippata in dati.zip"""

from zipfile import ZipFile
file_name = "dati.zip"

with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done1')

"""Importo varie librerie, tra cui di rilievo numpy e pandas e ovviamente tensorflow->keras"""

# Commented out IPython magic to ensure Python compatibility.
from tensorflow import keras
import pandas as pd
import re
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Flatten
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
# %matplotlib inline
import os
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorboard.plugins import projector
plt.style.use('ggplot')

tutti_gli_esercizi=[] #contenitore di tutte gli esercizi, sia di test che di training, mi servirà per fare embedding(non voglio che a stessi indici del vocabolario corrispondano parole diverse)

"""Leggo tutti i file di testo della cartella esercizi matematici, tramite un for itero ogni stringa di ogni file di testo e la metto in contenitori (1 per i dati di training, 1 per i dati di test e 1 per il validation set.

Le etichette saranno poi un indice da 1 a 7 con la seguente mappatura:

1) 3D geometric figures in spatial diagrams 

2) arithmetic

3) crypto-arithmetic

4) geometric figures in spatial diagrams OR puzzle

5) spatial reasoning

6) numbers in spatial diagrams

7) temporal reasoning
"""

lista_tutti_esercizi=[]
lista_labels=[]
esercizio=""
'''
2 vettori, uno per i testi e uno per le corrispettive etichette.  
'''
iter=1
while(iter<=70):
  esercizio=""
  with open("/content/Esercizi matematici_/train/3D geometric figures in spatial diagrams/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(1)
  
  with open("/content/Esercizi matematici_/train/arithmetic/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(2)

  with open("/content/Esercizi matematici_/train/crypto-arithmetic/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(3)

  if(iter<45 or iter>49):
    with open("/content/Esercizi matematici_/train/geometric figures in spatial diagrams OR puzzle/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+=line
    lista_tutti_esercizi.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels.append(4)

  if(iter<16 or iter>17):
    with open("/content/Esercizi matematici_/train/spatial reasoning/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+=line
    lista_tutti_esercizi.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels.append(5)

  with open("/content/Esercizi matematici_/train/numbers in spatial diagrams/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(6)

  with open("/content/Esercizi matematici_/train/temporal reasoning/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(7)

  iter+=1

'''dati di test'''
lista_tutti_esercizi_test=[]
lista_labels_test=[]
esercizio=""
iter=81
while(iter<=116):
  esercizio=""
  if(iter<=97):
    with open("/content/Esercizi matematici_/test/3D geometric figures in spatial diagrams/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(1)

  if(iter<=111):
    with open("/content/Esercizi matematici_/test/arithmetic/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(2)

  if(iter<=112):
    with open("/content/Esercizi matematici_/test/crypto-arithmetic/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(3)

  if(iter<100):
    with open("/content/Esercizi matematici_/test/geometric figures in spatial diagrams OR puzzle/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(4)

  if(iter<116):
    with open("/content/Esercizi matematici_/test/spatial reasoning/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(5)

  if(iter<=100):
    with open("/content/Esercizi matematici_/test/numbers in spatial diagrams/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(6)

  if(iter<=101):
    with open("/content/Esercizi matematici_/test/temporal reasoning/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(7)

  iter+=1

lista_tutti_esercizi_validation=[]
lista_labels_validation=[]
esercizio=""
'''

VALIDATION

'''
iter=71
while(iter<=80):
  esercizio=""
  with open("/content/Esercizi matematici_/validation/3D geometric figures in spatial diagrams/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi_validation.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels_validation.append(1)
  
  with open("/content/Esercizi matematici_/validation/arithmetic/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi_validation.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels_validation.append(2)

  with open("/content/Esercizi matematici_/validation/crypto-arithmetic/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi_validation.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels_validation.append(3)


  with open("/content/Esercizi matematici_/validation/geometric figures in spatial diagrams OR puzzle/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi_validation.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels_validation.append(4)


  with open("/content/Esercizi matematici_/validation/spatial reasoning/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi_validation.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels_validation.append(5)

  with open("/content/Esercizi matematici_/validation/numbers in spatial diagrams/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi_validation.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels_validation.append(6)

  with open("/content/Esercizi matematici_/validation/temporal reasoning/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi_validation.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels_validation.append(7)

  iter+=1

"""Inserisco i dati in un dataFrame, DataFrame di Pandas, così che mi si faciliti la loro gestione, ottenendo un'indicizzazione che ricorda un foglo excel"""

train_d={'esercizi':lista_tutti_esercizi,'etichette':lista_labels}
test_d={'esercizi':lista_tutti_esercizi_test,'etichette':lista_labels_test}

train_data = pd.DataFrame(data=train_d)
test_data = pd.DataFrame(data=test_d)

print(train_data)
print(test_data)

train_data['esercizi'] = train_data['esercizi'].apply(lambda x: x.lower()) # to lowercase
train_data['esercizi'] = train_data['esercizi'].apply((lambda x: re.sub('[^a-z\s]', '', x))) # remove all characters that are not in a-z
train_data['esercizi'] = train_data['esercizi'].replace(r'\n',' ', regex=True)


test_data['esercizi'] = test_data['esercizi'].apply(lambda x: x.lower()) # to lowercase
test_data['esercizi'] = test_data['esercizi'].apply((lambda x: re.sub('[^a-z\s]', '', x))) # remove all characters that are not in a-z
test_data['esercizi'] = test_data['esercizi'].replace(r'\n',' ', regex=True)

for i in range(len(tutti_gli_esercizi)):
  tutti_gli_esercizi[i] = tutti_gli_esercizi[i].lower()
  tutti_gli_esercizi[i] = re.sub('[^a-z\s]', '', tutti_gli_esercizi[i])
  tutti_gli_esercizi[i] = tutti_gli_esercizi[i].replace('\n',' ')

for i in range(len(lista_tutti_esercizi_validation)):
  lista_tutti_esercizi_validation[i] = lista_tutti_esercizi_validation[i].lower()
  lista_tutti_esercizi_validation[i] = re.sub('[^a-z\s]', '', lista_tutti_esercizi_validation[i])
  lista_tutti_esercizi_validation[i] = lista_tutti_esercizi_validation[i].replace('\n',' ')

print(train_data)
print(test_data)
print(tutti_gli_esercizi)
print(lista_tutti_esercizi_validation)

"""Scelta della dimensione dell'embedding: 100, che è convenzionale per Word2Vec"""

embed_dim = 100 # size of Word2Vec embeddings

"""Conteggio di tutte le parole che occorrono tra tutto il dataset(training+validation+test).

lista_tutte_parole= lista di tutte le parole, anche ripetute.

parole_training_no_dup = set, qui non sono dublicate le parole. Mi darà la grandezza del dizionario.
"""

lista_tutte_parole= []
for sentence in tutti_gli_esercizi:
    words = sentence.split()
    for word in words:
        lista_tutte_parole.append(word)

parole_training_no_dup= set(lista_tutte_parole)
print(parole_training_no_dup)

# number of unique words
words_number = len(parole_training_no_dup)

vocab_size = words_number # qui stabilisco grandezza dizionario


print(words_number)

"""Ora vado a tokenizzare il dizionario, fornendo padding sulla massima dimensione degli esercizi"""

tokenizer = Tokenizer(num_words=words_number, split=' ')
#tokenizer.fit_on_texts(train_data['esercizi'].values) # <= non posso fare, avrei per stesso indice del vocab parole diverse
tokenizer.fit_on_texts(tutti_gli_esercizi) # <= ATTENTION HERE!

X_train = tokenizer.texts_to_sequences(train_data['esercizi'].values)
X_train = pad_sequences(X_train)  # Padding to make sequences of same length
Y_train = pd.get_dummies(train_data['etichette']).values

print('train')
print(X_train)
print(Y_train)

# same for test data
#tokenizer.fit_on_texts(test_data['sentence'].values)
X_test = tokenizer.texts_to_sequences(test_data['esercizi'].values)
#X_test = pad_sequences(X_test)
X_test = pad_sequences(X_test,185)
Y_test = pd.get_dummies(test_data['etichette']).values

X_val= tokenizer.texts_to_sequences(lista_tutti_esercizi_validation)
X_val= pad_sequences(X_val,185)
Y_val = pd.get_dummies(lista_labels_validation)

print('test')
print(X_test)
print(Y_test)

# dictionary -> (word: integer)
wordindex_dict = tokenizer.word_index

model_gamma1 = keras.Sequential()
model_gamma1.add(keras.layers.Embedding(vocab_size, embed_dim, input_length=X_train.shape[1]))
model_gamma1.add(keras.layers.GlobalAveragePooling1D())
model_gamma1.add(keras.layers.Dense(16, activation=tf.nn.relu))
model_gamma1.add(Dense(7, activation='softmax'))

model_gamma1.summary()

model_gamma1.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model_gamma1.fit(X_train,
                    Y_train,
                    epochs=69,
                    batch_size=50,
                    validation_data=(X_val, Y_val),
                    verbose=1)

model_gamma1.predict(X_test)

results_gamma1 = model_gamma1.evaluate(X_test, Y_test)
print('test loss, test acc:', results_gamma1)

from gensim.models import Word2Vec
import numpy as np

# Define your dataset
dataset = parole_training_no_dup

# Train a Word2Vec model on the dataset
model = Word2Vec(dataset, min_count=1, size=100, window=5)

# Create a matrix of embeddings
embeddings_matrix = np.zeros((len(dataset), model.vector_size))
for i, sentence in enumerate(dataset):
    sentence_embedding = np.zeros(model.vector_size)
    n_words = 0
    for word in sentence:
        if word in model:
            sentence_embedding += model[word]
            n_words += 1
    if n_words > 0:
        sentence_embedding /= n_words
    embeddings_matrix[i] = sentence_embedding

# Print the embeddings matrix
print(embeddings_matrix)

"""lavoro ora con matrice di embeddings pre addestrata, sempre con schema del modello gamma 1"""

modello_delta = Sequential()
modello_delta.add(Embedding(vocab_size, embed_dim, weights=[embeddings_matrix], # Here we use the pre-trained embeddings
                    input_length=X_train.shape[1], trainable=True))
modello_delta.add(keras.layers.GlobalAveragePooling1D())
modello_delta.add(keras.layers.Dense(16, activation=tf.nn.relu))
modello_delta.add(Dense(7, activation='softmax'))

modello_delta.summary()

modello_delta.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = modello_delta.fit(X_train,
                    Y_train,
                    epochs=73,
                    batch_size=50,
                    validation_data=(X_val, Y_val),
                    verbose=1)

modello_delta.predict(X_test)

results_delta = modello_delta.evaluate(X_test, Y_test)
print('test loss, test acc:', results_delta)

"""Stampo ora il valore dei pesi ottenuti dopo l'addestramento dal modello delta"""

weights=[]
weights = tf.Variable(modello_delta.layers[0].get_weights()[0][0:])
print(weights)

"""Stampo la differenza tra pesi ottenuti dal training del modello e la matrice di embedding iniziale"""

diff_emb= weights - embeddings_matrix
print(diff_emb)

"""capiamo ora con quale accuratezza il modello delta farebbe predizione sui dati di training e sui dati di test e validation"""

modello_delta_2 = Sequential()
modello_delta_2.add(Embedding(vocab_size, embed_dim, weights=[embeddings_matrix], # Here we use the pre-trained embeddings
                    input_length=X_train.shape[1], trainable=False))
modello_delta_2.add(keras.layers.GlobalAveragePooling1D())
modello_delta_2.add(keras.layers.Dense(16, activation=tf.nn.relu))
modello_delta_2.add(Dense(7, activation='softmax'))

modello_delta_2.summary()

modello_delta_2.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = modello_delta_2.fit(X_train,
                    Y_train,
                    epochs=73,
                    batch_size=50,
                    validation_data=(X_val, Y_val),
                    verbose=1)

modello_delta_2.predict(X_test)

results_delta_2 = modello_delta_2.evaluate(X_test, Y_test)
print('test loss, test acc:', results_delta_2)

"""Modello delta_3:
  Provo a costruire nuovi layer, con struttura romboidale, per capire se facendo rimanere gli embedding inziali di word2vec, addestrando solo i pesi dei layer successivi a quelli dello strato di embedding, posso ottenere un modello che mi predice con un accuratezza accettabile.
"""

modello_delta_3 = Sequential()
modello_delta_3.add(Embedding(vocab_size, embed_dim, weights=[embeddings_matrix], # Here we use the pre-trained embeddings
                    input_length=X_train.shape[1], trainable=False))
modello_delta_3.add(keras.layers.GlobalAveragePooling1D())
modello_delta_3.add(keras.layers.Dense(7, activation=tf.nn.relu))
modello_delta_3.add(keras.layers.Dense(14, activation=tf.nn.relu))
modello_delta_3.add(keras.layers.Dense(28, activation=tf.nn.relu))
modello_delta_3.add(keras.layers.Dense(14, activation=tf.nn.relu))
modello_delta_3.add(Dense(7, activation='softmax'))

modello_delta_3.summary()

modello_delta_3.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = modello_delta_3.fit(X_train,
                    Y_train,
                    epochs=70,
                    batch_size=50,
                    validation_data=(X_val, Y_val),
                    verbose=1)

"""modello delta_4
provo a eliminare lo strato di GlobalAveragPooling. lo sostituisco con 4 strati LSTM (2 bidirezionale e 2 unidirezionali)

"""

lstm_out=10
modello_delta_4 = Sequential()
modello_delta_4.add(Embedding(vocab_size, embed_dim, weights=[embeddings_matrix], # Here we use the pre-trained embeddings
                    input_length=X_train.shape[1], trainable=False))
modello_delta_4.add(Bidirectional(LSTM(lstm_out, return_sequences=True, # this option must be used if we have more LSTM
                             activation='tanh', dropout=0.2, recurrent_dropout=0.2)))
modello_delta_4.add(LSTM(lstm_out, return_sequences=True))
modello_delta_4.add(Bidirectional(LSTM(lstm_out, return_sequences=True, # this option must be used if we have more LSTM
                             activation='tanh', dropout=0.2, recurrent_dropout=0.2)))
modello_delta_4.add(LSTM(lstm_out))
modello_delta_4.add(keras.layers.Dense(16, activation=tf.nn.relu))
modello_delta_4.add(Dense(7, activation='softmax'))

modello_delta_4.summary()

modello_delta_4.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = modello_delta_4.fit(X_train,
                    Y_train,
                    epochs=70,
                    batch_size=50,
                    validation_data=(X_val, Y_val),
                    verbose=1)

"""**In sintesi, mantenendo i valori degli embedding invariati, e provando vari modelli, anche con stessa struttura del gamma 1, non si riesce a costruire un modello che sappia predire gli esercizi matematici.
I valori restituiti dalla matrice di embedding dell'Word2Vec non riescono a coprire la rilevanza dei significati delle parole immerse in un contesto più tecnico, in termini di differenza di specificità dell'argomento proposto dall'esercizio. Sono infatti valori più generali e inerenti a un linguaggio non troppo dettagliato per questo specifico problema.**


**Bisogna quindi apprendere dei nuovi valori che ci qualificano le parole in ambiente più specifico, addestrando quindi necessariamente nuovi pesi per gli embeddings.**

Risultati:

con il modello gamma 1 il massimo risultato ottenuto in termini di accuratezza è stato con 70 epoche, avendo ottenuto un'accuratezza di:

*   0.9772 sui dati di training
*   0.7714 sul validation set (ultima epoca)
*   0.72 sui dati di test


con il modello delta 1 il massimo valore di accuratezza (considerando preponderanti i dati di test) è stato ottenuto per 72 epoche.
accuracy:

*   0.9607 sui dati di training
*   0.6143 sul validation set (ultima epoca)
*   0.7085 sui dati di test

Il fatto di addestrare il modello partendo da una matrice di embeddings, ottenuta tramite word2vec, non porta a maggiori livelli di accuratezza, anzi.
"""