# -*- coding: utf-8 -*-
"""Progetto_0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OutGdiywTD45n3NP_soDBbXxpR6GHBjY
"""

import tensorflow as tf
from tensorflow import keras

import numpy as np
from numpy import array

print(tf.__version__)

from zipfile import ZipFile
file_name = "dati.zip"

with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')

tutti_gli_esercizi=[] #contenitore di tutte gli esercizi, sia di test che di training, mi servirà per fare embedding(non voglio che a stessi indici del vocabolario corrispondano parole diverse)

lista_tutti_esercizi=[]
lista_labels=[]
esercizio=""
'''
2 vettori, uno per i testi e uno per le corrispettive etichette.  
'''
iter=1
while(iter<=70):
  esercizio=""
  with open("/content/Esercizi matematici_/train/3D geometric figures in spatial diagrams/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(1)
  
  with open("/content/Esercizi matematici_/train/arithmetic/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(2)

  with open("/content/Esercizi matematici_/train/crypto-arithmetic/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(3)

  if(iter<45 or iter>49):
    with open("/content/Esercizi matematici_/train/geometric figures in spatial diagrams OR puzzle/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+=line
    lista_tutti_esercizi.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels.append(4)

  if(iter<16 or iter>17):
    with open("/content/Esercizi matematici_/train/spatial reasoning/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+=line
    lista_tutti_esercizi.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels.append(5)

  with open("/content/Esercizi matematici_/train/numbers in spatial diagrams/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(6)

  with open("/content/Esercizi matematici_/train/temporal reasoning/"+str(iter)+".txt", "r") as f:
    parole_esercizio= f.readlines()
    for line in parole_esercizio:
      esercizio+=line
  lista_tutti_esercizi.append(esercizio)
  tutti_gli_esercizi.append(esercizio)
  esercizio=""
  lista_labels.append(7)

  iter+=1

'''dati di test'''
lista_tutti_esercizi_test=[]
lista_labels_test=[]
esercizio=""
iter=81
while(iter<=116):
  esercizio=""
  if(iter<=97):
    with open("/content/Esercizi matematici_/test/3D geometric figures in spatial diagrams/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(1)

  if(iter<=111):
    with open("/content/Esercizi matematici_/test/arithmetic/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(2)

  if(iter<=112):
    with open("/content/Esercizi matematici_/test/crypto-arithmetic/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(3)

  if(iter<100):
    with open("/content/Esercizi matematici_/test/geometric figures in spatial diagrams OR puzzle/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(4)

  if(iter<116):
    with open("/content/Esercizi matematici_/test/spatial reasoning/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(5)

  if(iter<=100):
    with open("/content/Esercizi matematici_/test/numbers in spatial diagrams/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(6)

  if(iter<=101):
    with open("/content/Esercizi matematici_/test/temporal reasoning/"+str(iter)+".txt", "r") as f:
      parole_esercizio= f.readlines()
      for line in parole_esercizio:
        esercizio+= line
    lista_tutti_esercizi_test.append(esercizio)
    tutti_gli_esercizi.append(esercizio)
    esercizio=""
    lista_labels_test.append(7)

  iter+=1

# Commented out IPython magic to ensure Python compatibility.
from tensorflow import keras
import pandas as pd
import re
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional, Flatten
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
# %matplotlib inline

"""Inserisco i dati in un dataFrame, DataFrame di Pandas, così che mi si faciliti la loro gestione, ottenendo un'indicizzazione che ricorda un foglo excel"""

train_d={'esercizi':lista_tutti_esercizi,'etichette':lista_labels}
test_d={'esercizi':lista_tutti_esercizi_test,'etichette':lista_labels_test}

train_data = pd.DataFrame(data=train_d)
test_data = pd.DataFrame(data=test_d)

print(train_data)
print(test_data)

"""Pulisco poi le mie frasi. (per ora tengo solo le parole)"""

train_data['esercizi'] = train_data['esercizi'].apply(lambda x: x.lower()) # to lowercase
train_data['esercizi'] = train_data['esercizi'].apply((lambda x: re.sub('[^a-z\s]', '', x))) # remove all characters that are not in a-z
train_data['esercizi'] = train_data['esercizi'].replace(r'\n',' ', regex=True)


test_data['esercizi'] = test_data['esercizi'].apply(lambda x: x.lower()) # to lowercase
test_data['esercizi'] = test_data['esercizi'].apply((lambda x: re.sub('[^a-z\s]', '', x))) # remove all characters that are not in a-z
test_data['esercizi'] = test_data['esercizi'].replace(r'\n',' ', regex=True)

for i in range(len(tutti_gli_esercizi)):
  tutti_gli_esercizi[i] = tutti_gli_esercizi[i].lower()
  tutti_gli_esercizi[i] = re.sub('[^a-z\s]', '', tutti_gli_esercizi[i])
  tutti_gli_esercizi[i] = tutti_gli_esercizi[i].replace('\n',' ')

print(train_data)
print(test_data)
print(tutti_gli_esercizi)

vocab_size = 500 # number of different words

tokenizer = Tokenizer(num_words=vocab_size, split=' ')
#tokenizer.fit_on_texts(train_data['esercizi'].values) # <= non posso fare, avrei per stesso indice del vocab parole diverse
tokenizer.fit_on_texts(tutti_gli_esercizi) # <= ATTENTION HERE!

X_train = tokenizer.texts_to_sequences(train_data['esercizi'].values)
X_train = pad_sequences(X_train)  # Padding to make sequences of same length
Y_train = pd.get_dummies(train_data['etichette']).values

print('train')
print(X_train)
print(Y_train)

# same for test data
#tokenizer.fit_on_texts(test_data['sentence'].values)
X_test = tokenizer.texts_to_sequences(test_data['esercizi'].values)
X_test = pad_sequences(X_test)
Y_test = pd.get_dummies(test_data['etichette']).values

print('test')
print(X_test)
print(Y_test)

embed_dim = 300 # size of Word2Vec embeddings
lstm_out = 10

model = Sequential()
model.add(Embedding(vocab_size, embed_dim, input_length=X_train.shape[1]))
model.add(LSTM(lstm_out, activation='tanh', dropout=0.2, recurrent_dropout=0.2))
model.add(tf.keras.layers.Dense(7, activation = 'softmax'))

#model.add(Dense(2, activation='softmax'))
#model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
#              metrics=['accuracy'])
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()

history = model.fit(X_train, Y_train, epochs=50, 
                    batch_size=50, verbose=2, shuffle= True)

fig, ax = plt.subplots()
ax.plot(history.history["loss"],'r', marker='.', label="Train Loss")
ax.plot(history.history["accuracy"],'g', marker='.', label="Train acc")
ax.legend()